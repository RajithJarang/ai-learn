{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor,transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.290283  [   64/60000]\n",
      "loss: 2.308031  [ 6464/60000]\n",
      "loss: 2.300972  [12864/60000]\n",
      "loss: 2.312832  [19264/60000]\n",
      "loss: 2.284213  [25664/60000]\n",
      "loss: 2.294189  [32064/60000]\n",
      "loss: 2.282643  [38464/60000]\n",
      "loss: 2.279778  [44864/60000]\n",
      "loss: 2.265897  [51264/60000]\n",
      "loss: 2.268418  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 16.6%, Avg loss: 2.269570 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.248504  [   64/60000]\n",
      "loss: 2.269897  [ 6464/60000]\n",
      "loss: 2.256348  [12864/60000]\n",
      "loss: 2.274717  [19264/60000]\n",
      "loss: 2.239985  [25664/60000]\n",
      "loss: 2.255733  [32064/60000]\n",
      "loss: 2.239436  [38464/60000]\n",
      "loss: 2.237978  [44864/60000]\n",
      "loss: 2.223223  [51264/60000]\n",
      "loss: 2.225871  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 26.7%, Avg loss: 2.227655 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.208121  [   64/60000]\n",
      "loss: 2.232937  [ 6464/60000]\n",
      "loss: 2.212958  [12864/60000]\n",
      "loss: 2.237232  [19264/60000]\n",
      "loss: 2.196191  [25664/60000]\n",
      "loss: 2.216962  [32064/60000]\n",
      "loss: 2.196232  [38464/60000]\n",
      "loss: 2.195815  [44864/60000]\n",
      "loss: 2.180043  [51264/60000]\n",
      "loss: 2.182185  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 2.184967 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.166904  [   64/60000]\n",
      "loss: 2.195169  [ 6464/60000]\n",
      "loss: 2.168546  [12864/60000]\n",
      "loss: 2.198280  [19264/60000]\n",
      "loss: 2.150351  [25664/60000]\n",
      "loss: 2.176113  [32064/60000]\n",
      "loss: 2.150888  [38464/60000]\n",
      "loss: 2.151164  [44864/60000]\n",
      "loss: 2.133943  [51264/60000]\n",
      "loss: 2.135605  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 2.139624 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.123102  [   64/60000]\n",
      "loss: 2.154873  [ 6464/60000]\n",
      "loss: 2.121408  [12864/60000]\n",
      "loss: 2.156584  [19264/60000]\n",
      "loss: 2.100697  [25664/60000]\n",
      "loss: 2.131623  [32064/60000]\n",
      "loss: 2.101389  [38464/60000]\n",
      "loss: 2.102624  [44864/60000]\n",
      "loss: 2.083820  [51264/60000]\n",
      "loss: 2.084471  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 2.090100 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.075349  [   64/60000]\n",
      "loss: 2.110721  [ 6464/60000]\n",
      "loss: 2.069989  [12864/60000]\n",
      "loss: 2.110741  [19264/60000]\n",
      "loss: 2.045898  [25664/60000]\n",
      "loss: 2.082023  [32064/60000]\n",
      "loss: 2.046908  [38464/60000]\n",
      "loss: 2.048738  [44864/60000]\n",
      "loss: 2.028773  [51264/60000]\n",
      "loss: 2.027357  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 2.035265 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.022897  [   64/60000]\n",
      "loss: 2.061721  [ 6464/60000]\n",
      "loss: 2.013088  [12864/60000]\n",
      "loss: 2.059639  [19264/60000]\n",
      "loss: 1.984771  [25664/60000]\n",
      "loss: 2.026367  [32064/60000]\n",
      "loss: 1.986528  [38464/60000]\n",
      "loss: 1.989217  [44864/60000]\n",
      "loss: 1.968405  [51264/60000]\n",
      "loss: 1.963935  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.4%, Avg loss: 1.974754 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.965619  [   64/60000]\n",
      "loss: 2.007373  [ 6464/60000]\n",
      "loss: 1.950137  [12864/60000]\n",
      "loss: 2.003520  [19264/60000]\n",
      "loss: 1.917507  [25664/60000]\n",
      "loss: 1.965091  [32064/60000]\n",
      "loss: 1.921019  [38464/60000]\n",
      "loss: 1.924332  [44864/60000]\n",
      "loss: 1.903227  [51264/60000]\n",
      "loss: 1.895358  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.909204 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.903691  [   64/60000]\n",
      "loss: 1.948337  [ 6464/60000]\n",
      "loss: 1.881648  [12864/60000]\n",
      "loss: 1.943151  [19264/60000]\n",
      "loss: 1.845162  [25664/60000]\n",
      "loss: 1.898544  [32064/60000]\n",
      "loss: 1.851924  [38464/60000]\n",
      "loss: 1.855059  [44864/60000]\n",
      "loss: 1.834697  [51264/60000]\n",
      "loss: 1.823082  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.839678 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.838112  [   64/60000]\n",
      "loss: 1.885339  [ 6464/60000]\n",
      "loss: 1.808497  [12864/60000]\n",
      "loss: 1.879876  [19264/60000]\n",
      "loss: 1.769263  [25664/60000]\n",
      "loss: 1.827893  [32064/60000]\n",
      "loss: 1.780889  [38464/60000]\n",
      "loss: 1.782429  [44864/60000]\n",
      "loss: 1.764410  [51264/60000]\n",
      "loss: 1.749012  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.767588 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.770239  [   64/60000]\n",
      "loss: 1.818942  [ 6464/60000]\n",
      "loss: 1.732380  [12864/60000]\n",
      "loss: 1.814461  [19264/60000]\n",
      "loss: 1.691914  [25664/60000]\n",
      "loss: 1.754420  [32064/60000]\n",
      "loss: 1.709431  [38464/60000]\n",
      "loss: 1.708459  [44864/60000]\n",
      "loss: 1.694522  [51264/60000]\n",
      "loss: 1.675177  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.694740 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.701827  [   64/60000]\n",
      "loss: 1.750955  [ 6464/60000]\n",
      "loss: 1.655161  [12864/60000]\n",
      "loss: 1.748819  [19264/60000]\n",
      "loss: 1.615166  [25664/60000]\n",
      "loss: 1.680105  [32064/60000]\n",
      "loss: 1.639505  [38464/60000]\n",
      "loss: 1.634895  [44864/60000]\n",
      "loss: 1.626813  [51264/60000]\n",
      "loss: 1.603846  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.622984 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.634429  [   64/60000]\n",
      "loss: 1.682804  [ 6464/60000]\n",
      "loss: 1.578834  [12864/60000]\n",
      "loss: 1.684213  [19264/60000]\n",
      "loss: 1.541025  [25664/60000]\n",
      "loss: 1.607396  [32064/60000]\n",
      "loss: 1.572688  [38464/60000]\n",
      "loss: 1.563489  [44864/60000]\n",
      "loss: 1.562412  [51264/60000]\n",
      "loss: 1.536212  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.553844 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.569350  [   64/60000]\n",
      "loss: 1.616288  [ 6464/60000]\n",
      "loss: 1.504988  [12864/60000]\n",
      "loss: 1.622062  [19264/60000]\n",
      "loss: 1.471120  [25664/60000]\n",
      "loss: 1.537782  [32064/60000]\n",
      "loss: 1.510067  [38464/60000]\n",
      "loss: 1.495638  [44864/60000]\n",
      "loss: 1.502175  [51264/60000]\n",
      "loss: 1.472989  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.488373 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.507586  [   64/60000]\n",
      "loss: 1.552706  [ 6464/60000]\n",
      "loss: 1.434590  [12864/60000]\n",
      "loss: 1.563112  [19264/60000]\n",
      "loss: 1.406270  [25664/60000]\n",
      "loss: 1.472534  [32064/60000]\n",
      "loss: 1.451701  [38464/60000]\n",
      "loss: 1.432169  [44864/60000]\n",
      "loss: 1.446282  [51264/60000]\n",
      "loss: 1.414651  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.427097 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.449650  [   64/60000]\n",
      "loss: 1.492664  [ 6464/60000]\n",
      "loss: 1.368222  [12864/60000]\n",
      "loss: 1.507828  [19264/60000]\n",
      "loss: 1.346664  [25664/60000]\n",
      "loss: 1.412413  [32064/60000]\n",
      "loss: 1.397433  [38464/60000]\n",
      "loss: 1.373346  [44864/60000]\n",
      "loss: 1.394830  [51264/60000]\n",
      "loss: 1.361275  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.370191 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.395497  [   64/60000]\n",
      "loss: 1.436283  [ 6464/60000]\n",
      "loss: 1.306066  [12864/60000]\n",
      "loss: 1.455981  [19264/60000]\n",
      "loss: 1.292191  [25664/60000]\n",
      "loss: 1.357337  [32064/60000]\n",
      "loss: 1.347389  [38464/60000]\n",
      "loss: 1.319198  [44864/60000]\n",
      "loss: 1.347592  [51264/60000]\n",
      "loss: 1.312543  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 1.317633 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.345047  [   64/60000]\n",
      "loss: 1.383517  [ 6464/60000]\n",
      "loss: 1.248235  [12864/60000]\n",
      "loss: 1.407659  [19264/60000]\n",
      "loss: 1.242553  [25664/60000]\n",
      "loss: 1.307243  [32064/60000]\n",
      "loss: 1.301361  [38464/60000]\n",
      "loss: 1.269483  [44864/60000]\n",
      "loss: 1.304273  [51264/60000]\n",
      "loss: 1.268165  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 1.269279 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.298223  [   64/60000]\n",
      "loss: 1.334294  [ 6464/60000]\n",
      "loss: 1.194511  [12864/60000]\n",
      "loss: 1.362796  [19264/60000]\n",
      "loss: 1.197627  [25664/60000]\n",
      "loss: 1.261875  [32064/60000]\n",
      "loss: 1.259018  [38464/60000]\n",
      "loss: 1.223957  [44864/60000]\n",
      "loss: 1.264440  [51264/60000]\n",
      "loss: 1.227695  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.224892 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.254684  [   64/60000]\n",
      "loss: 1.288529  [ 6464/60000]\n",
      "loss: 1.144753  [12864/60000]\n",
      "loss: 1.321154  [19264/60000]\n",
      "loss: 1.157043  [25664/60000]\n",
      "loss: 1.220805  [32064/60000]\n",
      "loss: 1.220165  [38464/60000]\n",
      "loss: 1.182239  [44864/60000]\n",
      "loss: 1.227916  [51264/60000]\n",
      "loss: 1.190620  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.184192 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.214245  [   64/60000]\n",
      "loss: 1.245997  [ 6464/60000]\n",
      "loss: 1.098748  [12864/60000]\n",
      "loss: 1.282672  [19264/60000]\n",
      "loss: 1.120426  [25664/60000]\n",
      "loss: 1.183589  [32064/60000]\n",
      "loss: 1.184436  [38464/60000]\n",
      "loss: 1.144003  [44864/60000]\n",
      "loss: 1.194370  [51264/60000]\n",
      "loss: 1.156573  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 1.146899 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.176709  [   64/60000]\n",
      "loss: 1.206562  [ 6464/60000]\n",
      "loss: 1.056225  [12864/60000]\n",
      "loss: 1.247057  [19264/60000]\n",
      "loss: 1.087416  [25664/60000]\n",
      "loss: 1.149723  [32064/60000]\n",
      "loss: 1.151734  [38464/60000]\n",
      "loss: 1.108955  [44864/60000]\n",
      "loss: 1.163419  [51264/60000]\n",
      "loss: 1.125320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.112707 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.141708  [   64/60000]\n",
      "loss: 1.170109  [ 6464/60000]\n",
      "loss: 1.016903  [12864/60000]\n",
      "loss: 1.214104  [19264/60000]\n",
      "loss: 1.057628  [25664/60000]\n",
      "loss: 1.118736  [32064/60000]\n",
      "loss: 1.121737  [38464/60000]\n",
      "loss: 1.076676  [44864/60000]\n",
      "loss: 1.134801  [51264/60000]\n",
      "loss: 1.096650  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.081343 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.109070  [   64/60000]\n",
      "loss: 1.136414  [ 6464/60000]\n",
      "loss: 0.980614  [12864/60000]\n",
      "loss: 1.183612  [19264/60000]\n",
      "loss: 1.030697  [25664/60000]\n",
      "loss: 1.090388  [32064/60000]\n",
      "loss: 1.094217  [38464/60000]\n",
      "loss: 1.047044  [44864/60000]\n",
      "loss: 1.108333  [51264/60000]\n",
      "loss: 1.070336  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 1.052549 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.078557  [   64/60000]\n",
      "loss: 1.105224  [ 6464/60000]\n",
      "loss: 0.947076  [12864/60000]\n",
      "loss: 1.155425  [19264/60000]\n",
      "loss: 1.006412  [25664/60000]\n",
      "loss: 1.064319  [32064/60000]\n",
      "loss: 1.068981  [38464/60000]\n",
      "loss: 1.019768  [44864/60000]\n",
      "loss: 1.083786  [51264/60000]\n",
      "loss: 1.046152  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 1.026083 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.049914  [   64/60000]\n",
      "loss: 1.076448  [ 6464/60000]\n",
      "loss: 0.916002  [12864/60000]\n",
      "loss: 1.129212  [19264/60000]\n",
      "loss: 0.984498  [25664/60000]\n",
      "loss: 1.040247  [32064/60000]\n",
      "loss: 1.045771  [38464/60000]\n",
      "loss: 0.994683  [44864/60000]\n",
      "loss: 1.060923  [51264/60000]\n",
      "loss: 1.023854  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.001722 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.023044  [   64/60000]\n",
      "loss: 1.049871  [ 6464/60000]\n",
      "loss: 0.887173  [12864/60000]\n",
      "loss: 1.104915  [19264/60000]\n",
      "loss: 0.964737  [25664/60000]\n",
      "loss: 1.017978  [32064/60000]\n",
      "loss: 1.024405  [38464/60000]\n",
      "loss: 0.971610  [44864/60000]\n",
      "loss: 1.039592  [51264/60000]\n",
      "loss: 1.003203  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.979264 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.997779  [   64/60000]\n",
      "loss: 1.025306  [ 6464/60000]\n",
      "loss: 0.860375  [12864/60000]\n",
      "loss: 1.082376  [19264/60000]\n",
      "loss: 0.946865  [25664/60000]\n",
      "loss: 0.997311  [32064/60000]\n",
      "loss: 1.004639  [38464/60000]\n",
      "loss: 0.950362  [44864/60000]\n",
      "loss: 1.019646  [51264/60000]\n",
      "loss: 0.984077  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.958519 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.974024  [   64/60000]\n",
      "loss: 1.002574  [ 6464/60000]\n",
      "loss: 0.835467  [12864/60000]\n",
      "loss: 1.061384  [19264/60000]\n",
      "loss: 0.930638  [25664/60000]\n",
      "loss: 0.978078  [32064/60000]\n",
      "loss: 0.986339  [38464/60000]\n",
      "loss: 0.930829  [44864/60000]\n",
      "loss: 1.000969  [51264/60000]\n",
      "loss: 0.966375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.939323 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.951581  [   64/60000]\n",
      "loss: 0.981518  [ 6464/60000]\n",
      "loss: 0.812271  [12864/60000]\n",
      "loss: 1.041829  [19264/60000]\n",
      "loss: 0.915869  [25664/60000]\n",
      "loss: 0.960092  [32064/60000]\n",
      "loss: 0.969392  [38464/60000]\n",
      "loss: 0.912811  [44864/60000]\n",
      "loss: 0.983504  [51264/60000]\n",
      "loss: 0.949963  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.921536 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.930369  [   64/60000]\n",
      "loss: 0.962036  [ 6464/60000]\n",
      "loss: 0.790685  [12864/60000]\n",
      "loss: 1.023616  [19264/60000]\n",
      "loss: 0.902398  [25664/60000]\n",
      "loss: 0.943233  [32064/60000]\n",
      "loss: 0.953737  [38464/60000]\n",
      "loss: 0.896188  [44864/60000]\n",
      "loss: 0.967157  [51264/60000]\n",
      "loss: 0.934702  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.905031 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.910318  [   64/60000]\n",
      "loss: 0.943959  [ 6464/60000]\n",
      "loss: 0.770563  [12864/60000]\n",
      "loss: 1.006634  [19264/60000]\n",
      "loss: 0.890127  [25664/60000]\n",
      "loss: 0.927469  [32064/60000]\n",
      "loss: 0.939229  [38464/60000]\n",
      "loss: 0.880874  [44864/60000]\n",
      "loss: 0.951857  [51264/60000]\n",
      "loss: 0.920480  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.889691 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.891332  [   64/60000]\n",
      "loss: 0.927208  [ 6464/60000]\n",
      "loss: 0.751739  [12864/60000]\n",
      "loss: 0.990770  [19264/60000]\n",
      "loss: 0.878859  [25664/60000]\n",
      "loss: 0.912692  [32064/60000]\n",
      "loss: 0.925733  [38464/60000]\n",
      "loss: 0.866742  [44864/60000]\n",
      "loss: 0.937516  [51264/60000]\n",
      "loss: 0.907197  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.875408 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.873355  [   64/60000]\n",
      "loss: 0.911620  [ 6464/60000]\n",
      "loss: 0.734107  [12864/60000]\n",
      "loss: 0.975894  [19264/60000]\n",
      "loss: 0.868438  [25664/60000]\n",
      "loss: 0.898806  [32064/60000]\n",
      "loss: 0.913138  [38464/60000]\n",
      "loss: 0.853712  [44864/60000]\n",
      "loss: 0.924057  [51264/60000]\n",
      "loss: 0.894774  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.862089 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.856288  [   64/60000]\n",
      "loss: 0.897046  [ 6464/60000]\n",
      "loss: 0.717611  [12864/60000]\n",
      "loss: 0.961919  [19264/60000]\n",
      "loss: 0.858755  [25664/60000]\n",
      "loss: 0.885726  [32064/60000]\n",
      "loss: 0.901388  [38464/60000]\n",
      "loss: 0.841689  [44864/60000]\n",
      "loss: 0.911410  [51264/60000]\n",
      "loss: 0.883138  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.849650 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.840101  [   64/60000]\n",
      "loss: 0.883452  [ 6464/60000]\n",
      "loss: 0.702148  [12864/60000]\n",
      "loss: 0.948880  [19264/60000]\n",
      "loss: 0.849760  [25664/60000]\n",
      "loss: 0.873391  [32064/60000]\n",
      "loss: 0.890391  [38464/60000]\n",
      "loss: 0.830567  [44864/60000]\n",
      "loss: 0.899532  [51264/60000]\n",
      "loss: 0.872234  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.838016 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.824746  [   64/60000]\n",
      "loss: 0.870749  [ 6464/60000]\n",
      "loss: 0.687657  [12864/60000]\n",
      "loss: 0.936692  [19264/60000]\n",
      "loss: 0.841406  [25664/60000]\n",
      "loss: 0.861732  [32064/60000]\n",
      "loss: 0.880075  [38464/60000]\n",
      "loss: 0.820288  [44864/60000]\n",
      "loss: 0.888397  [51264/60000]\n",
      "loss: 0.861991  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.827118 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.810190  [   64/60000]\n",
      "loss: 0.858853  [ 6464/60000]\n",
      "loss: 0.674078  [12864/60000]\n",
      "loss: 0.925249  [19264/60000]\n",
      "loss: 0.833606  [25664/60000]\n",
      "loss: 0.850717  [32064/60000]\n",
      "loss: 0.870407  [38464/60000]\n",
      "loss: 0.810784  [44864/60000]\n",
      "loss: 0.877955  [51264/60000]\n",
      "loss: 0.852355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.816895 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.796373  [   64/60000]\n",
      "loss: 0.847718  [ 6464/60000]\n",
      "loss: 0.661351  [12864/60000]\n",
      "loss: 0.914472  [19264/60000]\n",
      "loss: 0.826288  [25664/60000]\n",
      "loss: 0.840313  [32064/60000]\n",
      "loss: 0.861322  [38464/60000]\n",
      "loss: 0.802032  [44864/60000]\n",
      "loss: 0.868182  [51264/60000]\n",
      "loss: 0.843275  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.807291 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.783268  [   64/60000]\n",
      "loss: 0.837294  [ 6464/60000]\n",
      "loss: 0.649363  [12864/60000]\n",
      "loss: 0.904310  [19264/60000]\n",
      "loss: 0.819407  [25664/60000]\n",
      "loss: 0.830439  [32064/60000]\n",
      "loss: 0.852762  [38464/60000]\n",
      "loss: 0.793952  [44864/60000]\n",
      "loss: 0.858995  [51264/60000]\n",
      "loss: 0.834679  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.798249 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.770837  [   64/60000]\n",
      "loss: 0.827522  [ 6464/60000]\n",
      "loss: 0.638060  [12864/60000]\n",
      "loss: 0.894743  [19264/60000]\n",
      "loss: 0.812929  [25664/60000]\n",
      "loss: 0.821090  [32064/60000]\n",
      "loss: 0.844703  [38464/60000]\n",
      "loss: 0.786469  [44864/60000]\n",
      "loss: 0.850364  [51264/60000]\n",
      "loss: 0.826535  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.789730 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.759053  [   64/60000]\n",
      "loss: 0.818364  [ 6464/60000]\n",
      "loss: 0.627405  [12864/60000]\n",
      "loss: 0.885704  [19264/60000]\n",
      "loss: 0.806801  [25664/60000]\n",
      "loss: 0.812239  [32064/60000]\n",
      "loss: 0.837107  [38464/60000]\n",
      "loss: 0.779533  [44864/60000]\n",
      "loss: 0.842261  [51264/60000]\n",
      "loss: 0.818811  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.781687 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.747863  [   64/60000]\n",
      "loss: 0.809736  [ 6464/60000]\n",
      "loss: 0.617342  [12864/60000]\n",
      "loss: 0.877187  [19264/60000]\n",
      "loss: 0.801017  [25664/60000]\n",
      "loss: 0.803822  [32064/60000]\n",
      "loss: 0.829930  [38464/60000]\n",
      "loss: 0.773095  [44864/60000]\n",
      "loss: 0.834624  [51264/60000]\n",
      "loss: 0.811451  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.774085 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.737221  [   64/60000]\n",
      "loss: 0.801559  [ 6464/60000]\n",
      "loss: 0.607853  [12864/60000]\n",
      "loss: 0.869128  [19264/60000]\n",
      "loss: 0.795527  [25664/60000]\n",
      "loss: 0.795815  [32064/60000]\n",
      "loss: 0.823127  [38464/60000]\n",
      "loss: 0.767142  [44864/60000]\n",
      "loss: 0.827415  [51264/60000]\n",
      "loss: 0.804430  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.766887 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.727097  [   64/60000]\n",
      "loss: 0.793819  [ 6464/60000]\n",
      "loss: 0.598887  [12864/60000]\n",
      "loss: 0.861495  [19264/60000]\n",
      "loss: 0.790298  [25664/60000]\n",
      "loss: 0.788216  [32064/60000]\n",
      "loss: 0.816670  [38464/60000]\n",
      "loss: 0.761620  [44864/60000]\n",
      "loss: 0.820650  [51264/60000]\n",
      "loss: 0.797717  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.760062 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.717440  [   64/60000]\n",
      "loss: 0.786495  [ 6464/60000]\n",
      "loss: 0.590406  [12864/60000]\n",
      "loss: 0.854260  [19264/60000]\n",
      "loss: 0.785309  [25664/60000]\n",
      "loss: 0.780971  [32064/60000]\n",
      "loss: 0.810521  [38464/60000]\n",
      "loss: 0.756497  [44864/60000]\n",
      "loss: 0.814279  [51264/60000]\n",
      "loss: 0.791262  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.753578 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.708225  [   64/60000]\n",
      "loss: 0.779542  [ 6464/60000]\n",
      "loss: 0.582351  [12864/60000]\n",
      "loss: 0.847395  [19264/60000]\n",
      "loss: 0.780502  [25664/60000]\n",
      "loss: 0.774039  [32064/60000]\n",
      "loss: 0.804662  [38464/60000]\n",
      "loss: 0.751736  [44864/60000]\n",
      "loss: 0.808273  [51264/60000]\n",
      "loss: 0.785062  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.747412 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.699437  [   64/60000]\n",
      "loss: 0.772929  [ 6464/60000]\n",
      "loss: 0.574707  [12864/60000]\n",
      "loss: 0.840877  [19264/60000]\n",
      "loss: 0.775864  [25664/60000]\n",
      "loss: 0.767413  [32064/60000]\n",
      "loss: 0.799084  [38464/60000]\n",
      "loss: 0.747287  [44864/60000]\n",
      "loss: 0.802610  [51264/60000]\n",
      "loss: 0.779121  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.741541 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.691033  [   64/60000]\n",
      "loss: 0.766629  [ 6464/60000]\n",
      "loss: 0.567451  [12864/60000]\n",
      "loss: 0.834680  [19264/60000]\n",
      "loss: 0.771402  [25664/60000]\n",
      "loss: 0.761084  [32064/60000]\n",
      "loss: 0.793752  [38464/60000]\n",
      "loss: 0.743126  [44864/60000]\n",
      "loss: 0.797229  [51264/60000]\n",
      "loss: 0.773420  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.735941 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.683005  [   64/60000]\n",
      "loss: 0.760618  [ 6464/60000]\n",
      "loss: 0.560552  [12864/60000]\n",
      "loss: 0.828777  [19264/60000]\n",
      "loss: 0.767103  [25664/60000]\n",
      "loss: 0.755037  [32064/60000]\n",
      "loss: 0.788646  [38464/60000]\n",
      "loss: 0.739210  [44864/60000]\n",
      "loss: 0.792139  [51264/60000]\n",
      "loss: 0.767938  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.730593 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.675310  [   64/60000]\n",
      "loss: 0.754888  [ 6464/60000]\n",
      "loss: 0.553972  [12864/60000]\n",
      "loss: 0.823142  [19264/60000]\n",
      "loss: 0.762958  [25664/60000]\n",
      "loss: 0.749264  [32064/60000]\n",
      "loss: 0.783760  [38464/60000]\n",
      "loss: 0.735535  [44864/60000]\n",
      "loss: 0.787314  [51264/60000]\n",
      "loss: 0.762656  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.725478 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.667948  [   64/60000]\n",
      "loss: 0.749423  [ 6464/60000]\n",
      "loss: 0.547716  [12864/60000]\n",
      "loss: 0.817774  [19264/60000]\n",
      "loss: 0.758955  [25664/60000]\n",
      "loss: 0.743740  [32064/60000]\n",
      "loss: 0.779078  [38464/60000]\n",
      "loss: 0.732078  [44864/60000]\n",
      "loss: 0.782749  [51264/60000]\n",
      "loss: 0.757580  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.720581 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.660894  [   64/60000]\n",
      "loss: 0.744139  [ 6464/60000]\n",
      "loss: 0.541759  [12864/60000]\n",
      "loss: 0.812664  [19264/60000]\n",
      "loss: 0.755086  [25664/60000]\n",
      "loss: 0.738454  [32064/60000]\n",
      "loss: 0.774562  [38464/60000]\n",
      "loss: 0.728812  [44864/60000]\n",
      "loss: 0.778427  [51264/60000]\n",
      "loss: 0.752685  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.715886 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.654130  [   64/60000]\n",
      "loss: 0.739061  [ 6464/60000]\n",
      "loss: 0.536072  [12864/60000]\n",
      "loss: 0.807793  [19264/60000]\n",
      "loss: 0.751335  [25664/60000]\n",
      "loss: 0.733388  [32064/60000]\n",
      "loss: 0.770197  [38464/60000]\n",
      "loss: 0.725734  [44864/60000]\n",
      "loss: 0.774320  [51264/60000]\n",
      "loss: 0.747935  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.711382 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.647639  [   64/60000]\n",
      "loss: 0.734173  [ 6464/60000]\n",
      "loss: 0.530634  [12864/60000]\n",
      "loss: 0.803147  [19264/60000]\n",
      "loss: 0.747694  [25664/60000]\n",
      "loss: 0.728556  [32064/60000]\n",
      "loss: 0.766009  [38464/60000]\n",
      "loss: 0.722815  [44864/60000]\n",
      "loss: 0.770425  [51264/60000]\n",
      "loss: 0.743312  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.707051 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.641416  [   64/60000]\n",
      "loss: 0.729470  [ 6464/60000]\n",
      "loss: 0.525438  [12864/60000]\n",
      "loss: 0.798685  [19264/60000]\n",
      "loss: 0.744150  [25664/60000]\n",
      "loss: 0.723920  [32064/60000]\n",
      "loss: 0.761983  [38464/60000]\n",
      "loss: 0.720059  [44864/60000]\n",
      "loss: 0.766727  [51264/60000]\n",
      "loss: 0.738831  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.702884 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.635435  [   64/60000]\n",
      "loss: 0.724944  [ 6464/60000]\n",
      "loss: 0.520464  [12864/60000]\n",
      "loss: 0.794389  [19264/60000]\n",
      "loss: 0.740702  [25664/60000]\n",
      "loss: 0.719459  [32064/60000]\n",
      "loss: 0.758101  [38464/60000]\n",
      "loss: 0.717464  [44864/60000]\n",
      "loss: 0.763214  [51264/60000]\n",
      "loss: 0.734493  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.698870 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.629696  [   64/60000]\n",
      "loss: 0.720565  [ 6464/60000]\n",
      "loss: 0.515713  [12864/60000]\n",
      "loss: 0.790255  [19264/60000]\n",
      "loss: 0.737335  [25664/60000]\n",
      "loss: 0.715170  [32064/60000]\n",
      "loss: 0.754353  [38464/60000]\n",
      "loss: 0.714995  [44864/60000]\n",
      "loss: 0.759860  [51264/60000]\n",
      "loss: 0.730302  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.694998 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.624188  [   64/60000]\n",
      "loss: 0.716317  [ 6464/60000]\n",
      "loss: 0.511172  [12864/60000]\n",
      "loss: 0.786279  [19264/60000]\n",
      "loss: 0.734052  [25664/60000]\n",
      "loss: 0.711037  [32064/60000]\n",
      "loss: 0.750729  [38464/60000]\n",
      "loss: 0.712637  [44864/60000]\n",
      "loss: 0.756649  [51264/60000]\n",
      "loss: 0.726234  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.691257 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.618870  [   64/60000]\n",
      "loss: 0.712197  [ 6464/60000]\n",
      "loss: 0.506817  [12864/60000]\n",
      "loss: 0.782458  [19264/60000]\n",
      "loss: 0.730835  [25664/60000]\n",
      "loss: 0.707063  [32064/60000]\n",
      "loss: 0.747246  [38464/60000]\n",
      "loss: 0.710387  [44864/60000]\n",
      "loss: 0.753569  [51264/60000]\n",
      "loss: 0.722261  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.687641 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.613747  [   64/60000]\n",
      "loss: 0.708208  [ 6464/60000]\n",
      "loss: 0.502649  [12864/60000]\n",
      "loss: 0.778773  [19264/60000]\n",
      "loss: 0.727681  [25664/60000]\n",
      "loss: 0.703245  [32064/60000]\n",
      "loss: 0.743859  [38464/60000]\n",
      "loss: 0.708234  [44864/60000]\n",
      "loss: 0.750640  [51264/60000]\n",
      "loss: 0.718392  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.684142 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.608816  [   64/60000]\n",
      "loss: 0.704334  [ 6464/60000]\n",
      "loss: 0.498644  [12864/60000]\n",
      "loss: 0.775218  [19264/60000]\n",
      "loss: 0.724588  [25664/60000]\n",
      "loss: 0.699575  [32064/60000]\n",
      "loss: 0.740540  [38464/60000]\n",
      "loss: 0.706182  [44864/60000]\n",
      "loss: 0.747847  [51264/60000]\n",
      "loss: 0.714605  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.680751 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.604051  [   64/60000]\n",
      "loss: 0.700558  [ 6464/60000]\n",
      "loss: 0.494791  [12864/60000]\n",
      "loss: 0.771790  [19264/60000]\n",
      "loss: 0.721550  [25664/60000]\n",
      "loss: 0.696039  [32064/60000]\n",
      "loss: 0.737306  [38464/60000]\n",
      "loss: 0.704216  [44864/60000]\n",
      "loss: 0.745175  [51264/60000]\n",
      "loss: 0.710912  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.677465 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.599450  [   64/60000]\n",
      "loss: 0.696895  [ 6464/60000]\n",
      "loss: 0.491090  [12864/60000]\n",
      "loss: 0.768479  [19264/60000]\n",
      "loss: 0.718571  [25664/60000]\n",
      "loss: 0.692632  [32064/60000]\n",
      "loss: 0.734161  [38464/60000]\n",
      "loss: 0.702340  [44864/60000]\n",
      "loss: 0.742620  [51264/60000]\n",
      "loss: 0.707310  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.674274 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.595010  [   64/60000]\n",
      "loss: 0.693318  [ 6464/60000]\n",
      "loss: 0.487522  [12864/60000]\n",
      "loss: 0.765272  [19264/60000]\n",
      "loss: 0.715642  [25664/60000]\n",
      "loss: 0.689337  [32064/60000]\n",
      "loss: 0.731089  [38464/60000]\n",
      "loss: 0.700540  [44864/60000]\n",
      "loss: 0.740175  [51264/60000]\n",
      "loss: 0.703798  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.671173 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.590714  [   64/60000]\n",
      "loss: 0.689827  [ 6464/60000]\n",
      "loss: 0.484068  [12864/60000]\n",
      "loss: 0.762172  [19264/60000]\n",
      "loss: 0.712757  [25664/60000]\n",
      "loss: 0.686155  [32064/60000]\n",
      "loss: 0.728084  [38464/60000]\n",
      "loss: 0.698812  [44864/60000]\n",
      "loss: 0.737833  [51264/60000]\n",
      "loss: 0.700365  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.668157 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.586548  [   64/60000]\n",
      "loss: 0.686421  [ 6464/60000]\n",
      "loss: 0.480731  [12864/60000]\n",
      "loss: 0.759162  [19264/60000]\n",
      "loss: 0.709924  [25664/60000]\n",
      "loss: 0.683080  [32064/60000]\n",
      "loss: 0.725143  [38464/60000]\n",
      "loss: 0.697139  [44864/60000]\n",
      "loss: 0.735581  [51264/60000]\n",
      "loss: 0.697005  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.665223 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.582513  [   64/60000]\n",
      "loss: 0.683104  [ 6464/60000]\n",
      "loss: 0.477504  [12864/60000]\n",
      "loss: 0.756248  [19264/60000]\n",
      "loss: 0.707142  [25664/60000]\n",
      "loss: 0.680112  [32064/60000]\n",
      "loss: 0.722274  [38464/60000]\n",
      "loss: 0.695534  [44864/60000]\n",
      "loss: 0.733425  [51264/60000]\n",
      "loss: 0.693715  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.662367 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.578603  [   64/60000]\n",
      "loss: 0.679879  [ 6464/60000]\n",
      "loss: 0.474378  [12864/60000]\n",
      "loss: 0.753423  [19264/60000]\n",
      "loss: 0.704411  [25664/60000]\n",
      "loss: 0.677259  [32064/60000]\n",
      "loss: 0.719464  [38464/60000]\n",
      "loss: 0.693977  [44864/60000]\n",
      "loss: 0.731358  [51264/60000]\n",
      "loss: 0.690491  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.659583 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.574822  [   64/60000]\n",
      "loss: 0.676719  [ 6464/60000]\n",
      "loss: 0.471344  [12864/60000]\n",
      "loss: 0.750672  [19264/60000]\n",
      "loss: 0.701718  [25664/60000]\n",
      "loss: 0.674488  [32064/60000]\n",
      "loss: 0.716702  [38464/60000]\n",
      "loss: 0.692475  [44864/60000]\n",
      "loss: 0.729365  [51264/60000]\n",
      "loss: 0.687328  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.656867 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.571149  [   64/60000]\n",
      "loss: 0.673622  [ 6464/60000]\n",
      "loss: 0.468390  [12864/60000]\n",
      "loss: 0.747981  [19264/60000]\n",
      "loss: 0.699056  [25664/60000]\n",
      "loss: 0.671792  [32064/60000]\n",
      "loss: 0.713991  [38464/60000]\n",
      "loss: 0.691018  [44864/60000]\n",
      "loss: 0.727450  [51264/60000]\n",
      "loss: 0.684218  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.654216 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.567573  [   64/60000]\n",
      "loss: 0.670588  [ 6464/60000]\n",
      "loss: 0.465529  [12864/60000]\n",
      "loss: 0.745346  [19264/60000]\n",
      "loss: 0.696431  [25664/60000]\n",
      "loss: 0.669184  [32064/60000]\n",
      "loss: 0.711335  [38464/60000]\n",
      "loss: 0.689595  [44864/60000]\n",
      "loss: 0.725611  [51264/60000]\n",
      "loss: 0.681156  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.651627 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.564095  [   64/60000]\n",
      "loss: 0.667606  [ 6464/60000]\n",
      "loss: 0.462749  [12864/60000]\n",
      "loss: 0.742774  [19264/60000]\n",
      "loss: 0.693831  [25664/60000]\n",
      "loss: 0.666644  [32064/60000]\n",
      "loss: 0.708736  [38464/60000]\n",
      "loss: 0.688201  [44864/60000]\n",
      "loss: 0.723840  [51264/60000]\n",
      "loss: 0.678154  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.649095 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.560720  [   64/60000]\n",
      "loss: 0.664692  [ 6464/60000]\n",
      "loss: 0.460028  [12864/60000]\n",
      "loss: 0.740263  [19264/60000]\n",
      "loss: 0.691253  [25664/60000]\n",
      "loss: 0.664172  [32064/60000]\n",
      "loss: 0.706175  [38464/60000]\n",
      "loss: 0.686842  [44864/60000]\n",
      "loss: 0.722137  [51264/60000]\n",
      "loss: 0.675216  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.646619 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.557428  [   64/60000]\n",
      "loss: 0.661847  [ 6464/60000]\n",
      "loss: 0.457387  [12864/60000]\n",
      "loss: 0.737799  [19264/60000]\n",
      "loss: 0.688702  [25664/60000]\n",
      "loss: 0.661765  [32064/60000]\n",
      "loss: 0.703654  [38464/60000]\n",
      "loss: 0.685524  [44864/60000]\n",
      "loss: 0.720515  [51264/60000]\n",
      "loss: 0.672330  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.644197 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.554210  [   64/60000]\n",
      "loss: 0.659061  [ 6464/60000]\n",
      "loss: 0.454826  [12864/60000]\n",
      "loss: 0.735392  [19264/60000]\n",
      "loss: 0.686182  [25664/60000]\n",
      "loss: 0.659432  [32064/60000]\n",
      "loss: 0.701184  [38464/60000]\n",
      "loss: 0.684247  [44864/60000]\n",
      "loss: 0.718951  [51264/60000]\n",
      "loss: 0.669494  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.641827 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.551067  [   64/60000]\n",
      "loss: 0.656328  [ 6464/60000]\n",
      "loss: 0.452331  [12864/60000]\n",
      "loss: 0.733039  [19264/60000]\n",
      "loss: 0.683701  [25664/60000]\n",
      "loss: 0.657163  [32064/60000]\n",
      "loss: 0.698749  [38464/60000]\n",
      "loss: 0.682997  [44864/60000]\n",
      "loss: 0.717450  [51264/60000]\n",
      "loss: 0.666692  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.639507 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.548002  [   64/60000]\n",
      "loss: 0.653652  [ 6464/60000]\n",
      "loss: 0.449885  [12864/60000]\n",
      "loss: 0.730731  [19264/60000]\n",
      "loss: 0.681265  [25664/60000]\n",
      "loss: 0.654956  [32064/60000]\n",
      "loss: 0.696354  [38464/60000]\n",
      "loss: 0.681786  [44864/60000]\n",
      "loss: 0.715995  [51264/60000]\n",
      "loss: 0.663914  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.637235 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.545017  [   64/60000]\n",
      "loss: 0.651035  [ 6464/60000]\n",
      "loss: 0.447495  [12864/60000]\n",
      "loss: 0.728470  [19264/60000]\n",
      "loss: 0.678858  [25664/60000]\n",
      "loss: 0.652796  [32064/60000]\n",
      "loss: 0.693991  [38464/60000]\n",
      "loss: 0.680627  [44864/60000]\n",
      "loss: 0.714591  [51264/60000]\n",
      "loss: 0.661179  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.635009 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.542105  [   64/60000]\n",
      "loss: 0.648469  [ 6464/60000]\n",
      "loss: 0.445159  [12864/60000]\n",
      "loss: 0.726254  [19264/60000]\n",
      "loss: 0.676491  [25664/60000]\n",
      "loss: 0.650682  [32064/60000]\n",
      "loss: 0.691665  [38464/60000]\n",
      "loss: 0.679498  [44864/60000]\n",
      "loss: 0.713223  [51264/60000]\n",
      "loss: 0.658481  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.632827 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.539255  [   64/60000]\n",
      "loss: 0.645944  [ 6464/60000]\n",
      "loss: 0.442876  [12864/60000]\n",
      "loss: 0.724085  [19264/60000]\n",
      "loss: 0.674150  [25664/60000]\n",
      "loss: 0.648625  [32064/60000]\n",
      "loss: 0.689360  [38464/60000]\n",
      "loss: 0.678402  [44864/60000]\n",
      "loss: 0.711892  [51264/60000]\n",
      "loss: 0.655831  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.630686 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.536474  [   64/60000]\n",
      "loss: 0.643463  [ 6464/60000]\n",
      "loss: 0.440641  [12864/60000]\n",
      "loss: 0.721962  [19264/60000]\n",
      "loss: 0.671844  [25664/60000]\n",
      "loss: 0.646617  [32064/60000]\n",
      "loss: 0.687099  [38464/60000]\n",
      "loss: 0.677326  [44864/60000]\n",
      "loss: 0.710599  [51264/60000]\n",
      "loss: 0.653233  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.628584 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.533756  [   64/60000]\n",
      "loss: 0.641025  [ 6464/60000]\n",
      "loss: 0.438452  [12864/60000]\n",
      "loss: 0.719874  [19264/60000]\n",
      "loss: 0.669585  [25664/60000]\n",
      "loss: 0.644662  [32064/60000]\n",
      "loss: 0.684885  [38464/60000]\n",
      "loss: 0.676277  [44864/60000]\n",
      "loss: 0.709345  [51264/60000]\n",
      "loss: 0.650680  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.626522 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.531093  [   64/60000]\n",
      "loss: 0.638633  [ 6464/60000]\n",
      "loss: 0.436320  [12864/60000]\n",
      "loss: 0.717826  [19264/60000]\n",
      "loss: 0.667353  [25664/60000]\n",
      "loss: 0.642746  [32064/60000]\n",
      "loss: 0.682701  [38464/60000]\n",
      "loss: 0.675250  [44864/60000]\n",
      "loss: 0.708134  [51264/60000]\n",
      "loss: 0.648176  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.624497 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.528477  [   64/60000]\n",
      "loss: 0.636289  [ 6464/60000]\n",
      "loss: 0.434247  [12864/60000]\n",
      "loss: 0.715823  [19264/60000]\n",
      "loss: 0.665143  [25664/60000]\n",
      "loss: 0.640870  [32064/60000]\n",
      "loss: 0.680549  [38464/60000]\n",
      "loss: 0.674258  [44864/60000]\n",
      "loss: 0.706961  [51264/60000]\n",
      "loss: 0.645719  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.622507 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.525914  [   64/60000]\n",
      "loss: 0.633992  [ 6464/60000]\n",
      "loss: 0.432220  [12864/60000]\n",
      "loss: 0.713859  [19264/60000]\n",
      "loss: 0.662960  [25664/60000]\n",
      "loss: 0.639045  [32064/60000]\n",
      "loss: 0.678420  [38464/60000]\n",
      "loss: 0.673291  [44864/60000]\n",
      "loss: 0.705821  [51264/60000]\n",
      "loss: 0.643288  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.620552 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.523405  [   64/60000]\n",
      "loss: 0.631729  [ 6464/60000]\n",
      "loss: 0.430234  [12864/60000]\n",
      "loss: 0.711928  [19264/60000]\n",
      "loss: 0.660798  [25664/60000]\n",
      "loss: 0.637261  [32064/60000]\n",
      "loss: 0.676319  [38464/60000]\n",
      "loss: 0.672343  [44864/60000]\n",
      "loss: 0.704711  [51264/60000]\n",
      "loss: 0.640893  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.618630 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.520942  [   64/60000]\n",
      "loss: 0.629498  [ 6464/60000]\n",
      "loss: 0.428286  [12864/60000]\n",
      "loss: 0.710020  [19264/60000]\n",
      "loss: 0.658661  [25664/60000]\n",
      "loss: 0.635514  [32064/60000]\n",
      "loss: 0.674246  [38464/60000]\n",
      "loss: 0.671408  [44864/60000]\n",
      "loss: 0.703620  [51264/60000]\n",
      "loss: 0.638537  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.616740 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.518523  [   64/60000]\n",
      "loss: 0.627302  [ 6464/60000]\n",
      "loss: 0.426374  [12864/60000]\n",
      "loss: 0.708145  [19264/60000]\n",
      "loss: 0.656547  [25664/60000]\n",
      "loss: 0.633809  [32064/60000]\n",
      "loss: 0.672186  [38464/60000]\n",
      "loss: 0.670504  [44864/60000]\n",
      "loss: 0.702568  [51264/60000]\n",
      "loss: 0.636201  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.614882 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.516148  [   64/60000]\n",
      "loss: 0.625141  [ 6464/60000]\n",
      "loss: 0.424503  [12864/60000]\n",
      "loss: 0.706313  [19264/60000]\n",
      "loss: 0.654447  [25664/60000]\n",
      "loss: 0.632147  [32064/60000]\n",
      "loss: 0.670156  [38464/60000]\n",
      "loss: 0.669617  [44864/60000]\n",
      "loss: 0.701546  [51264/60000]\n",
      "loss: 0.633893  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.613055 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.513815  [   64/60000]\n",
      "loss: 0.623015  [ 6464/60000]\n",
      "loss: 0.422668  [12864/60000]\n",
      "loss: 0.704519  [19264/60000]\n",
      "loss: 0.652377  [25664/60000]\n",
      "loss: 0.630521  [32064/60000]\n",
      "loss: 0.668151  [38464/60000]\n",
      "loss: 0.668747  [44864/60000]\n",
      "loss: 0.700546  [51264/60000]\n",
      "loss: 0.631615  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.611257 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.511529  [   64/60000]\n",
      "loss: 0.620923  [ 6464/60000]\n",
      "loss: 0.420871  [12864/60000]\n",
      "loss: 0.702740  [19264/60000]\n",
      "loss: 0.650329  [25664/60000]\n",
      "loss: 0.628917  [32064/60000]\n",
      "loss: 0.666175  [38464/60000]\n",
      "loss: 0.667901  [44864/60000]\n",
      "loss: 0.699571  [51264/60000]\n",
      "loss: 0.629382  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.609488 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.509295  [   64/60000]\n",
      "loss: 0.618860  [ 6464/60000]\n",
      "loss: 0.419109  [12864/60000]\n",
      "loss: 0.700983  [19264/60000]\n",
      "loss: 0.648293  [25664/60000]\n",
      "loss: 0.627343  [32064/60000]\n",
      "loss: 0.664215  [38464/60000]\n",
      "loss: 0.667064  [44864/60000]\n",
      "loss: 0.698619  [51264/60000]\n",
      "loss: 0.627177  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.607746 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.507108  [   64/60000]\n",
      "loss: 0.616832  [ 6464/60000]\n",
      "loss: 0.417377  [12864/60000]\n",
      "loss: 0.699252  [19264/60000]\n",
      "loss: 0.646283  [25664/60000]\n",
      "loss: 0.625809  [32064/60000]\n",
      "loss: 0.662274  [38464/60000]\n",
      "loss: 0.666243  [44864/60000]\n",
      "loss: 0.697687  [51264/60000]\n",
      "loss: 0.625002  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.606031 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.504958  [   64/60000]\n",
      "loss: 0.614837  [ 6464/60000]\n",
      "loss: 0.415671  [12864/60000]\n",
      "loss: 0.697551  [19264/60000]\n",
      "loss: 0.644285  [25664/60000]\n",
      "loss: 0.624313  [32064/60000]\n",
      "loss: 0.660363  [38464/60000]\n",
      "loss: 0.665435  [44864/60000]\n",
      "loss: 0.696776  [51264/60000]\n",
      "loss: 0.622853  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.604342 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.502841  [   64/60000]\n",
      "loss: 0.612877  [ 6464/60000]\n",
      "loss: 0.413998  [12864/60000]\n",
      "loss: 0.695870  [19264/60000]\n",
      "loss: 0.642309  [25664/60000]\n",
      "loss: 0.622851  [32064/60000]\n",
      "loss: 0.658473  [38464/60000]\n",
      "loss: 0.664628  [44864/60000]\n",
      "loss: 0.695887  [51264/60000]\n",
      "loss: 0.620732  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.602679 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.500751  [   64/60000]\n",
      "loss: 0.610947  [ 6464/60000]\n",
      "loss: 0.412356  [12864/60000]\n",
      "loss: 0.694213  [19264/60000]\n",
      "loss: 0.640362  [25664/60000]\n",
      "loss: 0.621415  [32064/60000]\n",
      "loss: 0.656612  [38464/60000]\n",
      "loss: 0.663836  [44864/60000]\n",
      "loss: 0.695021  [51264/60000]\n",
      "loss: 0.618637  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.601042 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.498699  [   64/60000]\n",
      "loss: 0.609050  [ 6464/60000]\n",
      "loss: 0.410747  [12864/60000]\n",
      "loss: 0.692579  [19264/60000]\n",
      "loss: 0.638440  [25664/60000]\n",
      "loss: 0.619995  [32064/60000]\n",
      "loss: 0.654766  [38464/60000]\n",
      "loss: 0.663064  [44864/60000]\n",
      "loss: 0.694172  [51264/60000]\n",
      "loss: 0.616572  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.599429 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.496689  [   64/60000]\n",
      "loss: 0.607182  [ 6464/60000]\n",
      "loss: 0.409162  [12864/60000]\n",
      "loss: 0.690971  [19264/60000]\n",
      "loss: 0.636542  [25664/60000]\n",
      "loss: 0.618594  [32064/60000]\n",
      "loss: 0.652941  [38464/60000]\n",
      "loss: 0.662303  [44864/60000]\n",
      "loss: 0.693348  [51264/60000]\n",
      "loss: 0.614539  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.597840 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.494715  [   64/60000]\n",
      "loss: 0.605342  [ 6464/60000]\n",
      "loss: 0.407602  [12864/60000]\n",
      "loss: 0.689370  [19264/60000]\n",
      "loss: 0.634663  [25664/60000]\n",
      "loss: 0.617208  [32064/60000]\n",
      "loss: 0.651134  [38464/60000]\n",
      "loss: 0.661563  [44864/60000]\n",
      "loss: 0.692546  [51264/60000]\n",
      "loss: 0.612532  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.596275 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
